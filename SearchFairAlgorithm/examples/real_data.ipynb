{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair Binary Classification with SearchFair on CelebA and Adult\n",
    "\n",
    "Here, we show how to use SearchFair on two datasets: CelebA and Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We start by importing SearchFair from the installed package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchfair import SearchFair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we load some necessary methods and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# The optimization does not always comply with the new cvxpy dpp disciplined programming rules. \n",
    "# but this is not a problem. \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CelebA dataset\n",
    "\n",
    "On the Celebrity Faces dataset we are given descriptions of celebrity faces, with 40 binary attributes. Here, we use the Attribute 'Smiling' as the class label, and sex as the sensitive attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_real_data as get_data\n",
    "\n",
    "# Load Data\n",
    "x_data, y_data, s_data = get_data.get_celebA_data(load_data_size=None)\n",
    "# Train Test split. Here, we choose a small number to reduce running time.\n",
    "train_size = 1200\n",
    "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=train_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some basic information about the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 202599\n",
      "# non-protected examples: 118165\n",
      "# protected examples: 84434\n",
      "# non-protected examples in positive class: 63871 (54.1%)\n",
      "# protected examples in positive class: 33798 (40.0%)\n"
     ]
    }
   ],
   "source": [
    "import utils as ut\n",
    "ut.print_data_stats(s_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a SearchFair Model\n",
    "\n",
    "### Demographic Parity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn a classifier with SearchFair, we need to choose a kernel between 'linear' and 'rbf', and we need to choose a fairness notion - either Demographic Parity (DDP) or Equality of Opportunity (DEO). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_notion = 'DDP' # DDP = Demographic Parity, DEO = Equality of Opportunity. \n",
    "kernel = 'linear' # 'linear', 'rbf'\n",
    "verbose = 2 # True = SearchFair output, 2 = show also solver progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us choose a regularization parameter and then fit a model with the default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Testing lambda_min: 0.00\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                    v1.1.11                                    \n",
      "===============================================================================\n",
      "(CVXPY) Apr 07 05:09:48 PM: Your problem has 1200 variables, 0 constraints, and 2880000 parameters.\n",
      "(CVXPY) Apr 07 05:09:48 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Apr 07 05:09:48 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Apr 07 05:09:48 PM: Compiling problem (target solver=SCS).\n",
      "(CVXPY) Apr 07 05:09:48 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> SCS\n",
      "(CVXPY) Apr 07 05:09:48 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) Apr 07 05:09:48 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Apr 07 05:09:48 PM: Applying reduction ConeMatrixStuffing\n"
     ]
    }
   ],
   "source": [
    "# Regularization Parameter beta\n",
    "reg_beta = 0.0001\n",
    "linear_model_DDP = SearchFair(reg_beta=reg_beta, kernel=kernel, fairness_notion=fairness_notion, verbose=verbose, stop_criterion=0.01)\n",
    "start = time()\n",
    "linear_model_DDP.fit(x_train, y_train, s_train=s_train)\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print out the Accuracy and the fairness notions Demographic Parity and Equality of Opportuniy, we define the following function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clf_stats(model, x_train, x_test, y_train, y_test, s_train, s_test):\n",
    "    train_acc = ut.get_accuracy(np.sign(model.predict(x_train)), y_train)\n",
    "    test_acc = ut.get_accuracy(np.sign(model.predict(x_test)), y_test)\n",
    "    test_DDP, test_DEO = ut.compute_fairness_measures(model.predict(x_test), y_test, s_test)\n",
    "    train_DDP, train_DEO = ut.compute_fairness_measures(model.predict(x_train), y_train, s_train)\n",
    "\n",
    "    print(10*'-'+\"Train\"+10*'-')\n",
    "    print(\"Accuracy: %0.4f%%\" % (train_acc * 100))\n",
    "    print(\"DDP: %0.4f%%\" % (train_DDP * 100), \"DEO: %0.4f%%\" % (train_DEO * 100))\n",
    "    print(10*'-'+\"Test\"+10*'-')\n",
    "    print(\"Accuracy: %0.4f%%\" % (test_acc * 100))\n",
    "    print(\"DDP: %0.4f%%\" % (test_DDP * 100), \"DEO: %0.4f%%\" % (test_DEO * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see, if we obtained a fair classifier with respect to the fairness notions we specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Train----------\n",
      "Accuracy: 81.3333%\n",
      "DDP: 3.0748% DEO: 4.6921%\n",
      "----------Test----------\n",
      "Accuracy: 78.8817%\n",
      "DDP: 2.9439% DEO: 13.9502%\n"
     ]
    }
   ],
   "source": [
    "print_clf_stats(linear_model_DDP, x_train, x_test, y_train, y_test, s_train, s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train DDP is small, and SearchFair succeeded to find a fair classifier. The test DDP might or might not be close to 0. This is due to the small number of points which are used to reduce running time for this example notebook. Go ahead and try it with more points!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equality of Opportunity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try the same using a more complex rbf kernel, and we try to improve Equality of Opportunity this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Testing lambda_min: 0.00\n",
      "Obtained: DEO = 0.1191 with lambda = 0.0000\n",
      "Testing lambda_max: 1.00\n",
      "Obtained: DEO = -0.8856 with lambda = 1.0000\n",
      "Starting Binary Search...\n",
      "----------Iteration #0----------\n",
      "Testing new Lambda: 0.5000\n",
      "Obtained: DEO = -0.8429 with lambda = 0.5000\n",
      "----------Iteration #1----------\n",
      "Testing new Lambda: 0.2500\n",
      "Obtained: DEO = -0.2191 with lambda = 0.2500\n",
      "----------Iteration #2----------\n",
      "Testing new Lambda: 0.1250\n",
      "Obtained: DEO = 0.0570 with lambda = 0.1250\n",
      "----------Iteration #3----------\n",
      "Testing new Lambda: 0.1875\n",
      "Obtained: DEO = -0.0286 with lambda = 0.1875\n",
      "----------Iteration #4----------\n",
      "Testing new Lambda: 0.1562\n",
      "Obtained: DEO = 0.0275 with lambda = 0.1562\n",
      "----------Iteration #5----------\n",
      "Testing new Lambda: 0.1719\n",
      "Obtained: DEO = 0.0193 with lambda = 0.1719\n",
      "----------Iteration #6----------\n",
      "Testing new Lambda: 0.1797\n",
      "Obtained: DEO = 0.0033 with lambda = 0.1797\n",
      "Sufficient fairness obtained before maximum iterations were reached.\n",
      "----------Found Lambda 0.1797 with fairness 0.0033----------\n",
      "----------Train----------\n",
      "Accuracy: 84.8333%\n",
      "DDP: 10.5714% DEO: 0.3337%\n",
      "----------Test----------\n",
      "Accuracy: 84.8177%\n",
      "DDP: 13.6207% DEO: 10.1459%\n"
     ]
    }
   ],
   "source": [
    "fairness_notion = 'DEO' # DDP = Demographic Parity, DEO = Equality of Opportunity. \n",
    "kernel = 'rbf' # 'linear', 'rbf'\n",
    "verbose = True\n",
    "\n",
    "# Regularization Parameter beta\n",
    "reg_beta = 0.0001\n",
    "rbf_model_DEO = SearchFair(reg_beta=reg_beta, kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
    "rbf_model_DEO.fit(x_train, y_train, s_train=s_train)\n",
    "\n",
    "# Evaluate model\n",
    "print_clf_stats(rbf_model_DEO, x_train, x_test, y_train, y_test, s_train, s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use GridSearchCV for the regularization paramter beta, and, if used, the width of the rbf kernel. But running this might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    }
   ],
   "source": [
    "fairness_notion = 'DDP' # DDP = Demographic Parity, DEO = Equality of Opportunity. \n",
    "kernel = 'rbf' # 'linear', 'rbf'\n",
    "verbose = False\n",
    "\n",
    "cv_model = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
    "\n",
    "# regularization parameter beta\n",
    "beta_params = [0.0001, 0.001, 0.01]\n",
    "cv_params = {'reg_beta': beta_params}\n",
    "\n",
    "if kernel == 'rbf':\n",
    "    n_features = x_data.shape[1]\n",
    "    default_width = 1/n_features\n",
    "    order_of_magn = np.floor(np.log10(default_width))\n",
    "    kernel_widths = [10**(order_of_magn), default_width, 10**(order_of_magn+1)]\n",
    "    cv_params['gamma'] = kernel_widths\n",
    "\n",
    "grid_clf = GridSearchCV(cv_model,cv_params, cv=3, verbose=1, n_jobs=1, scoring='accuracy', refit=True)\n",
    "grid_clf.fit(x_train, y_train, s_train=s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Train----------\n",
      "Accuracy: 86.1667%\n",
      "DDP: -0.5068% DEO: -1.1536%\n",
      "----------Test----------\n",
      "Accuracy: 82.5481%\n",
      "DDP: -0.9058% DEO: -4.7941%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print_clf_stats(grid_clf, x_train, x_test, y_train, y_test, s_train, s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult dataset\n",
    "\n",
    "In the fairness literature, the adult dataset is a very popular dataset. It contains US census data from 1994, where the class label indicates if the income is higher or lower than 50.000$. The binary sensitive attribute here, is the sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 48842\n",
      "# non-protected examples: 32650\n",
      "# protected examples: 16192\n",
      "# non-protected examples in positive class: 9918 (30.4%)\n",
      "# protected examples in positive class: 1769 (10.9%)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "x_data, y_data, s_data = get_data.get_adult_data(load_data_size=None)\n",
    "# Train Test split. Here, we choose a small number to reduce running time.\n",
    "train_size = 1200\n",
    "x_train, x_test, y_train, y_test, s_train, s_test = train_test_split(x_data, y_data, s_data, train_size=train_size, shuffle=True)\n",
    "ut.print_data_stats(s_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can also try SearchFair on Adult. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier is fair enough with lambda = 1.0000\n",
      "Classifier is fair enough with lambda = 1.0000\n",
      "Classifier is fair enough with lambda = 1.0000\n",
      "Classifier is fair enough with lambda = 1.0000\n",
      "Classifier is fair enough with lambda = 1.0000\n",
      "Classifier is fair enough with lambda = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 71.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SearchFair(kernel='rbf'), n_jobs=1,\n",
       "             param_grid={'gamma': [0.01, 0.05555555555555555, 0.1],\n",
       "                         'reg_beta': [0.0001, 0.001, 0.01]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_notion = 'DDP' # DDP = Demographic Parity, DEO = Equality of Opportunity. \n",
    "kernel = 'rbf' # 'linear', 'rbf'\n",
    "verbose = False\n",
    "\n",
    "cv_model_adult = SearchFair(kernel=kernel, fairness_notion=fairness_notion, verbose=verbose)\n",
    "\n",
    "# regularization parameter beta\n",
    "beta_params = [0.0001, 0.001, 0.01]\n",
    "cv_params = {'reg_beta': beta_params}\n",
    "\n",
    "if kernel == 'rbf':\n",
    "    n_features = x_data.shape[1]\n",
    "    default_width = 1/n_features\n",
    "    order_of_magn = np.floor(np.log10(default_width))\n",
    "    kernel_widths = [10**(order_of_magn), default_width, 10**(order_of_magn+1)]\n",
    "    cv_params['gamma'] = kernel_widths\n",
    "\n",
    "grid_clf = GridSearchCV(cv_model_adult,cv_params, cv=3, verbose=1, n_jobs=1, scoring='accuracy')\n",
    "grid_clf.fit(x_train, y_train, s_train=s_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Train----------\n",
      "Accuracy: 76.1667%\n",
      "DDP: 0.0000% DEO: 0.0000%\n",
      "----------Test----------\n",
      "Accuracy: 76.0694%\n",
      "DDP: 0.0000% DEO: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print_clf_stats(grid_clf, x_train, x_test, y_train, y_test, s_train, s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
